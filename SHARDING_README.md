# Work Items Sharding for Parallel Processing

This document explains the new sharding functionality that distributes work items across matrix builds for parallel execution.

## Overview

The enhanced CI/CD pipeline now supports automatic partitioning (sharding) of work items into separate batches that can be processed in parallel using GitHub Actions matrix builds.

## Architecture

### Original Flow
```
Producer → Consumer (Sequential Processing)
```

### New Matrix Flow
```
Producer → Shard Generator → Matrix Consumer Jobs (Parallel Processing) → Combiner
```

## Components

### 1. Shard Generator (`shard_workitems.py`)
- Reads work items generated by the producer
- Partitions them into configurable number of batches
- Creates individual shard files for each batch
- Generates GitHub Actions matrix configuration

### 2. Sharded Consumer Task (`sharded_consumer`)
- New task in `tasks.py` that processes a specific shard
- Uses `SHARD_ID` environment variable to identify which shard to process
- Generates individual ZIP archives per shard
- Creates detailed processing reports

### 3. Matrix Workflow (`.github/workflows/fetch-robocorp-matrix.yaml`)
- New GitHub Actions workflow with matrix strategy
- Runs multiple consumer jobs in parallel
- Combines results from all shards
- Generates comprehensive final report

## Usage

### Running the Matrix Workflow

1. **Manual Trigger**: Use the GitHub Actions interface
   - Navigate to Actions → "Robocorp ARC Producer-Consumer Matrix Workflow"
   - Click "Run workflow"
   - Specify:
     - `org_name`: GitHub organization to fetch repos from
     - `max_workers`: Number of parallel workers (default: 4)

2. **Workflow Steps**:
   - **Producer**: Fetches repositories and creates work items
   - **Shard**: Partitions work items into batches
   - **Consumer Matrix**: Processes batches in parallel
   - **Combine**: Aggregates results and generates final report

### Local Testing

Test the sharding functionality locally:

```bash
# Test with 4 workers
python3 shard_workitems.py devdata/work-items-out/run-1/work-items.json 4 devdata/test-shards

# Test with different worker counts
./test_sharding.sh
```

### Configuration Options

#### Matrix Workflow Parameters
- `org_name`: GitHub organization name (required)
- `max_workers`: Maximum parallel workers (default: 4)
- `max-parallel`: GitHub Actions matrix concurrency limit (default: 4)

#### Sharding Script Parameters
```bash
python3 shard_workitems.py <work_items_file> [max_workers] [output_dir]
```

## File Structure

```
.github/workflows/
├── fetch-robocorp.yaml           # Original sequential workflow
└── fetch-robocorp-matrix.yaml    # New matrix workflow

devdata/
├── env-for-sharded-consumer.json # Environment config for sharded consumer
└── shards/                       # Generated shard files

shard_workitems.py                 # Sharding utility script
tasks.py                          # Contains sharded_consumer task
```

## Benefits

### Performance Improvements
- **Parallel Processing**: Multiple repositories cloned simultaneously
- **Scalable**: Configurable number of workers based on workload
- **Efficient Resource Usage**: Better utilization of available runners

### Reliability Improvements
- **Isolation**: Failures in one shard don't affect others
- **Detailed Reporting**: Per-shard and combined processing reports
- **Resilience**: Failed shards can be retried independently

### Example Performance Gains
- **37 repositories**: 
  - Sequential: ~37 clone operations in series
  - Matrix (4 workers): ~10 clone operations per worker in parallel
  - Estimated speedup: 3-4x faster execution

## Output Artifacts

### Matrix Workflow Outputs
- `producer-output`: Original producer results
- `sharded-work-items`: Partitioned work item files
- `output-shard-{N}-{org}`: Individual shard results
- `final-output-{org}`: Combined final results with comprehensive report

### Reports Generated
- **Shard Reports**: `shard-{N}-report.json` per worker
- **Combined Report**: `combined-report.json` with aggregated statistics

## Example Combined Report
```json
{
  "org_name": "joshyorko",
  "total_shards": 4,
  "total_repositories_processed": 37,
  "total_successful_clones": 35,
  "total_failed_clones": 2,
  "success_rate": 94.59,
  "shard_reports": [...]
}
```

## Troubleshooting

### Common Issues

1. **No work items to shard**: 
   - Ensure producer ran successfully
   - Check work items file exists and has valid data

2. **Matrix job failures**:
   - Check individual shard reports for specific errors
   - Review GitHub Actions logs for each matrix job

3. **Sharding script errors**:
   - Verify Python environment and dependencies
   - Check file paths and permissions

### Debugging Tips

- Use local testing script to verify sharding logic
- Check shard file contents for proper distribution
- Review matrix configuration generation
- Monitor GitHub Actions runner capacity

## Migration from Sequential Workflow

To migrate from the original sequential workflow:

1. **Keep Both Workflows**: Original workflow remains available as fallback
2. **Test with Small Datasets**: Start with smaller organizations
3. **Monitor Performance**: Compare execution times and success rates
4. **Adjust Workers**: Tune `max_workers` based on runner capacity

## Future Enhancements

Potential improvements for the sharding system:

- **Dynamic Sharding**: Adjust shard size based on repository characteristics
- **Smart Distribution**: Balance shards by repository size or complexity
- **Retry Logic**: Automatic retry of failed shards
- **Resource Optimization**: Adaptive worker allocation based on queue depth
